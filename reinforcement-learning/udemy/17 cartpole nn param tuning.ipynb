{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "\n",
    "import math, random, time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.Tensor\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "seed_value = 23\n",
    "env.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "learning_rate = 0.02\n",
    "num_episodes = 500\n",
    "gamma = 1\n",
    "\n",
    "hidden_layer = 64\n",
    "\n",
    "egreedy = 0.9\n",
    "egreedy_final = 0\n",
    "egreedy_decay = 500\n",
    "\n",
    "report_interval = 10\n",
    "score_to_solve = 195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_inputs = env.observation_space.shape[0]\n",
    "number_of_outputs = env.action_space.n\n",
    "\n",
    "def calculate_epsilon(steps_done):\n",
    "    return egreedy_final + (egreedy - egreedy_final) * math.exp(-1 * steps_done / egreedy_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(number_of_inputs, hidden_layer)\n",
    "        self.linear2 = nn.Linear(hidden_layer, number_of_outputs)\n",
    "        self.activation = nn.Tanh()\n",
    "#         self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output1 = self.linear1(x)\n",
    "        output1 = self.activation(output1)\n",
    "        return self.linear2(output1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetAgent(object):\n",
    "    def __init__(self):\n",
    "        self.nn = NeuralNetwork()\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(params=self.nn.parameters(), lr=learning_rate)\n",
    "        \n",
    "    def select_action(self, state, epsion):\n",
    "        random_for_egreedy = torch.rand(1)[0]\n",
    "        \n",
    "        if random_for_egreedy > epsilon:\n",
    "            with torch.no_grad():\n",
    "                state = Tensor(state)\n",
    "                action_from_nn = self.nn(state)\n",
    "                action = torch.max(action_from_nn, 0)[1]\n",
    "                action = action.item()\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def optimize(self, state, action, new_state, reward, done):\n",
    "        state = Tensor(state)\n",
    "        new_state = Tensor(new_state)\n",
    "        reward = Tensor([reward])\n",
    "        \n",
    "        if done:\n",
    "            target_value = reward\n",
    "        else:\n",
    "            new_state_values = self.nn(new_state).detach()\n",
    "            max_new_state_values = torch.max(new_state_values)\n",
    "            target_value = reward + gamma * max_new_state_values\n",
    "            \n",
    "        predicted_value = self.nn(state)[action]\n",
    "        loss = self.loss_func(predicted_value, target_value)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Episode 0 ***                       \n",
      "Av.reward: [last 10]: 1.20, [last 100]: 0.12, [all]: 12.00                       \n",
      "epsilon: 0.88, frames_total: 12\n",
      "Elapsed time:  16:17:1550611064\n",
      "\n",
      "*** Episode 10 ***                       \n",
      "Av.reward: [last 10]: 23.20, [last 100]: 2.44, [all]: 22.18                       \n",
      "epsilon: 0.55, frames_total: 244\n",
      "Elapsed time:  16:17:1550611064\n",
      "\n",
      "*** Episode 20 ***                       \n",
      "Av.reward: [last 10]: 36.40, [last 100]: 6.08, [all]: 28.95                       \n",
      "epsilon: 0.27, frames_total: 608\n",
      "Elapsed time:  16:17:1550611064\n",
      "\n",
      "*** Episode 30 ***                       \n",
      "Av.reward: [last 10]: 56.30, [last 100]: 11.71, [all]: 37.77                       \n",
      "epsilon: 0.09, frames_total: 1171\n",
      "Elapsed time:  16:17:1550611064\n",
      "\n",
      "*** Episode 40 ***                       \n",
      "Av.reward: [last 10]: 37.20, [last 100]: 15.43, [all]: 37.63                       \n",
      "epsilon: 0.04, frames_total: 1543\n",
      "Elapsed time:  16:17:1550611065\n",
      "\n",
      "*** Episode 50 ***                       \n",
      "Av.reward: [last 10]: 64.30, [last 100]: 21.86, [all]: 42.86                       \n",
      "epsilon: 0.01, frames_total: 2186\n",
      "Elapsed time:  16:17:1550611065\n",
      "\n",
      "*** Episode 60 ***                       \n",
      "Av.reward: [last 10]: 84.10, [last 100]: 30.27, [all]: 49.62                       \n",
      "epsilon: 0.00, frames_total: 3027\n",
      "Elapsed time:  16:17:1550611065\n",
      "\n",
      "*** Episode 70 ***                       \n",
      "Av.reward: [last 10]: 130.20, [last 100]: 43.29, [all]: 60.97                       \n",
      "epsilon: 0.00, frames_total: 4329\n",
      "Elapsed time:  16:17:1550611066\n",
      "\n",
      "*** Episode 80 ***                       \n",
      "Av.reward: [last 10]: 161.80, [last 100]: 59.47, [all]: 73.42                       \n",
      "epsilon: 0.00, frames_total: 5947\n",
      "Elapsed time:  16:17:1550611067\n",
      "\n",
      "*** Episode 90 ***                       \n",
      "Av.reward: [last 10]: 156.30, [last 100]: 75.10, [all]: 82.53                       \n",
      "epsilon: 0.00, frames_total: 7510\n",
      "Elapsed time:  16:17:1550611068\n",
      "\n",
      "*** Episode 100 ***                       \n",
      "Av.reward: [last 10]: 149.90, [last 100]: 89.97, [all]: 89.20                       \n",
      "epsilon: 0.00, frames_total: 9009\n",
      "Elapsed time:  16:17:1550611069\n",
      "\n",
      "*** Episode 110 ***                       \n",
      "Av.reward: [last 10]: 170.60, [last 100]: 104.71, [all]: 96.53                       \n",
      "epsilon: 0.00, frames_total: 10715\n",
      "Elapsed time:  16:17:1550611070\n",
      "\n",
      "*** Episode 120 ***                       \n",
      "Av.reward: [last 10]: 180.10, [last 100]: 119.08, [all]: 103.44                       \n",
      "epsilon: 0.00, frames_total: 12516\n",
      "Elapsed time:  16:17:1550611071\n",
      "\n",
      "*** Episode 130 ***                       \n",
      "Av.reward: [last 10]: 136.60, [last 100]: 127.11, [all]: 105.97                       \n",
      "epsilon: 0.00, frames_total: 13882\n",
      "Elapsed time:  16:17:1550611072\n",
      "\n",
      "*** Episode 140 ***                       \n",
      "Av.reward: [last 10]: 176.00, [last 100]: 140.99, [all]: 110.94                       \n",
      "epsilon: 0.00, frames_total: 15642\n",
      "Elapsed time:  16:17:1550611073\n",
      "\n",
      "*** Episode 150 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 154.56, [all]: 116.83                       \n",
      "epsilon: 0.00, frames_total: 17642\n",
      "Elapsed time:  16:17:1550611075\n",
      "\n",
      "*** Episode 160 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 166.15, [all]: 122.00                       \n",
      "epsilon: 0.00, frames_total: 19642\n",
      "Elapsed time:  16:17:1550611076\n",
      "\n",
      "*** Episode 170 ***                       \n",
      "Av.reward: [last 10]: 143.80, [last 100]: 167.51, [all]: 123.27                       \n",
      "epsilon: 0.00, frames_total: 21080\n",
      "Elapsed time:  16:17:1550611077\n",
      "\n",
      "*** Episode 180 ***                       \n",
      "Av.reward: [last 10]: 194.10, [last 100]: 170.74, [all]: 127.19                       \n",
      "epsilon: 0.00, frames_total: 23021\n",
      "Elapsed time:  16:17:1550611078\n",
      "\n",
      "*** Episode 190 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 175.11, [all]: 131.00                       \n",
      "epsilon: 0.00, frames_total: 25021\n",
      "Elapsed time:  16:17:1550611079\n",
      "\n",
      "*** Episode 200 ***                       \n",
      "Av.reward: [last 10]: 186.10, [last 100]: 178.73, [all]: 133.74                       \n",
      "epsilon: 0.00, frames_total: 26882\n",
      "Elapsed time:  16:18:1550611080\n",
      "\n",
      "*** Episode 210 ***                       \n",
      "Av.reward: [last 10]: 185.60, [last 100]: 180.23, [all]: 136.20                       \n",
      "epsilon: 0.00, frames_total: 28738\n",
      "Elapsed time:  16:18:1550611081\n",
      "\n",
      "*** Episode 220 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 182.22, [all]: 139.09                       \n",
      "epsilon: 0.00, frames_total: 30738\n",
      "Elapsed time:  16:18:1550611082\n",
      "\n",
      "*** Episode 230 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 188.56, [all]: 141.72                       \n",
      "epsilon: 0.00, frames_total: 32738\n",
      "Elapsed time:  16:18:1550611084\n",
      "\n",
      "*** Episode 240 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 190.96, [all]: 144.14                       \n",
      "epsilon: 0.00, frames_total: 34738\n",
      "Elapsed time:  16:18:1550611085\n",
      "\n",
      "*** Episode 250 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 190.96, [all]: 146.37                       \n",
      "epsilon: 0.00, frames_total: 36738\n",
      "Elapsed time:  16:18:1550611086\n",
      "\n",
      "*** Episode 260 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 190.96, [all]: 148.42                       \n",
      "epsilon: 0.00, frames_total: 38738\n",
      "Elapsed time:  16:18:1550611087\n",
      "Solved after %i episodes 267\n",
      "\n",
      "*** Episode 270 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 196.58, [all]: 150.32                       \n",
      "epsilon: 0.00, frames_total: 40738\n",
      "Elapsed time:  16:18:1550611089\n",
      "\n",
      "*** Episode 280 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 197.17, [all]: 152.09                       \n",
      "epsilon: 0.00, frames_total: 42738\n",
      "Elapsed time:  16:18:1550611090\n",
      "\n",
      "*** Episode 290 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 197.17, [all]: 153.74                       \n",
      "epsilon: 0.00, frames_total: 44738\n",
      "Elapsed time:  16:18:1550611091\n",
      "\n",
      "*** Episode 300 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 198.56, [all]: 155.28                       \n",
      "epsilon: 0.00, frames_total: 46738\n",
      "Elapsed time:  16:18:1550611092\n",
      "\n",
      "*** Episode 310 ***                       \n",
      "Av.reward: [last 10]: 199.90, [last 100]: 199.99, [all]: 156.71                       \n",
      "epsilon: 0.00, frames_total: 48737\n",
      "Elapsed time:  16:18:1550611093\n",
      "\n",
      "*** Episode 320 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 158.06                       \n",
      "epsilon: 0.00, frames_total: 50737\n",
      "Elapsed time:  16:18:1550611095\n",
      "\n",
      "*** Episode 330 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 159.33                       \n",
      "epsilon: 0.00, frames_total: 52737\n",
      "Elapsed time:  16:18:1550611096\n",
      "\n",
      "*** Episode 340 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 160.52                       \n",
      "epsilon: 0.00, frames_total: 54737\n",
      "Elapsed time:  16:18:1550611097\n",
      "\n",
      "*** Episode 350 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 161.64                       \n",
      "epsilon: 0.00, frames_total: 56737\n",
      "Elapsed time:  16:18:1550611098\n",
      "\n",
      "*** Episode 360 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 162.71                       \n",
      "epsilon: 0.00, frames_total: 58737\n",
      "Elapsed time:  16:18:1550611099\n",
      "\n",
      "*** Episode 370 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 163.71                       \n",
      "epsilon: 0.00, frames_total: 60737\n",
      "Elapsed time:  16:18:1550611100\n",
      "\n",
      "*** Episode 380 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 164.66                       \n",
      "epsilon: 0.00, frames_total: 62737\n",
      "Elapsed time:  16:18:1550611102\n",
      "\n",
      "*** Episode 390 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 165.57                       \n",
      "epsilon: 0.00, frames_total: 64737\n",
      "Elapsed time:  16:18:1550611103\n",
      "\n",
      "*** Episode 400 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.99, [all]: 166.43                       \n",
      "epsilon: 0.00, frames_total: 66737\n",
      "Elapsed time:  16:18:1550611104\n",
      "\n",
      "*** Episode 410 ***                       \n",
      "Av.reward: [last 10]: 196.20, [last 100]: 199.62, [all]: 167.15                       \n",
      "epsilon: 0.00, frames_total: 68699\n",
      "Elapsed time:  16:18:1550611105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Episode 420 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.62, [all]: 167.93                       \n",
      "epsilon: 0.00, frames_total: 70699\n",
      "Elapsed time:  16:18:1550611107\n",
      "\n",
      "*** Episode 430 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.62, [all]: 168.68                       \n",
      "epsilon: 0.00, frames_total: 72699\n",
      "Elapsed time:  16:18:1550611108\n",
      "\n",
      "*** Episode 440 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.62, [all]: 169.39                       \n",
      "epsilon: 0.00, frames_total: 74699\n",
      "Elapsed time:  16:18:1550611109\n",
      "\n",
      "*** Episode 450 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.62, [all]: 170.06                       \n",
      "epsilon: 0.00, frames_total: 76699\n",
      "Elapsed time:  16:18:1550611110\n",
      "\n",
      "*** Episode 460 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.62, [all]: 170.71                       \n",
      "epsilon: 0.00, frames_total: 78699\n",
      "Elapsed time:  16:18:1550611111\n",
      "\n",
      "*** Episode 470 ***                       \n",
      "Av.reward: [last 10]: 200.00, [last 100]: 199.62, [all]: 171.34                       \n",
      "epsilon: 0.00, frames_total: 80699\n",
      "Elapsed time:  16:18:1550611113\n",
      "\n",
      "*** Episode 480 ***                       \n",
      "Av.reward: [last 10]: 197.50, [last 100]: 199.37, [all]: 171.88                       \n",
      "epsilon: 0.00, frames_total: 82674\n",
      "Elapsed time:  16:18:1550611114\n",
      "\n",
      "*** Episode 490 ***                       \n",
      "Av.reward: [last 10]: 195.50, [last 100]: 198.92, [all]: 172.36                       \n",
      "epsilon: 0.00, frames_total: 84629\n",
      "Elapsed time:  16:18:1550611115\n",
      "Average reward: 172.86\n",
      "Average number of steps (last 100 episodes): 198.92\n",
      "Solved after 267 episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112c30400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qnet_agent = QNetAgent()\n",
    "\n",
    "steps_total = []\n",
    "frames_total = 0\n",
    "solved_after = 0\n",
    "solved = False\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "        frames_total += 1\n",
    "        \n",
    "        epsilon = calculate_epsilon(frames_total)\n",
    "        \n",
    "        action = qnet_agent.select_action(state, epsilon)\n",
    "        \n",
    "        new_state, reward, done, total = env.step(action)\n",
    "        \n",
    "        qnet_agent.optimize(state, action, new_state, reward, done)\n",
    "        \n",
    "        state = new_state\n",
    "        \n",
    "        if done:\n",
    "            steps_total.append(step)\n",
    "            mean_reward_100 = sum(steps_total[-100:])/100\n",
    "            \n",
    "            if (mean_reward_100 > score_to_solve and solved == False):\n",
    "                print(\"Solved after %i episodes\", i_episode)\n",
    "                solved_after = i_episode\n",
    "                solved = True\n",
    "            if(i_episode % report_interval == 0):\n",
    "                print(\"\\n*** Episode %i *** \\\n",
    "                      \\nAv.reward: [last %i]: %.2f, [last 100]: %.2f, [all]: %.2f \\\n",
    "                      \\nepsilon: %.2f, frames_total: %i\" \n",
    "                  % \n",
    "                  ( i_episode,\n",
    "                    report_interval,\n",
    "                    sum(steps_total[-report_interval:])/report_interval,\n",
    "                    mean_reward_100,\n",
    "                    sum(steps_total)/len(steps_total),\n",
    "                    epsilon,\n",
    "                    frames_total\n",
    "                          ) \n",
    "                  )\n",
    "\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(\"Elapsed time: \", time.strftime(\"%H:%M:%s\"))\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"Average reward: %.2f\" % (sum(steps_total)/num_episodes))\n",
    "print(\"Average number of steps (last 100 episodes): %.2f\" % (sum(steps_total[-100:])/100))\n",
    "if solved:\n",
    "      print(\"Solved after %i episodes\" % solved_after)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(\"Rewards\")\n",
    "plt.bar(torch.arange(len(steps_total)), steps_total, alpha=0.6, color='red')\n",
    "plt.show()\n",
    "      \n",
    "env.close()\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
