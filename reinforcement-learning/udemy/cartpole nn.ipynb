{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "\n",
    "import math, random, time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.Tensor\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "seed_value = 23\n",
    "env.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "learning_rate = 0.01\n",
    "hidden_layer = 64\n",
    "num_episodes = 500\n",
    "gamma = 0.85\n",
    "\n",
    "egreedy = 0.9\n",
    "egreedy_final = 0.02\n",
    "egreedy_decay = 500\n",
    "\n",
    "report_interval = 10\n",
    "score_to_solve = 195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_inputs = env.observation_space.shape[0]\n",
    "number_of_outputs = env.action_space.n\n",
    "\n",
    "def calculate_epsilon(steps_done):\n",
    "    return egreedy_final + (egreedy - egreedy_final) * math.exp(-1 * steps_done / egreedy_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(number_of_inputs, hidden_layer)\n",
    "        self.linear2 = nn.Linear(hidden_layer, number_of_outputs)\n",
    "        self.activation = nn.Tanh()\n",
    "#         self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output1 = self.linear1(x)\n",
    "        output1 = self.activation(output1)\n",
    "        return self.linear2(output1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetAgent(object):\n",
    "    def __init__(self):\n",
    "        self.nn = NeuralNetwork() #.to(device)\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(params=self.nn.parameters(), lr=learning_rate)\n",
    "        \n",
    "    def select_action(self, state, epsion):\n",
    "        random_for_egreedy = torch.rand(1)[0]\n",
    "        \n",
    "        if random_for_egreedy > epsilon:\n",
    "            with torch.no_grad():\n",
    "                state = Tensor(state) #.to(device)\n",
    "                action_from_nn = self.nn(state)\n",
    "                action = torch.max(action_from_nn, 0)[1]\n",
    "                action = action.item()\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def optimize(self, state, action, new_state, reward, done):\n",
    "        state = Tensor(state) #.to(device)\n",
    "        new_state = Tensor(new_state) #.to(device)\n",
    "        reward = Tensor([reward]) #.to(device)\n",
    "        \n",
    "        if done:\n",
    "            target_value = reward\n",
    "        else:\n",
    "            new_state_values = self.nn(new_state).detach()\n",
    "            max_new_state_values = torch.max(new_state_values)\n",
    "            target_value = reward + gamma * max_new_state_values\n",
    "            \n",
    "        predicted_value = self.nn(state)[action]\n",
    "        loss = self.loss_func(predicted_value, target_value)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Episode 0 ***                       \n",
      "Av.reward: [last 10]: 4.40, [last 100]: 0.44, [all]: 44.00                       \n",
      "epsilon: 0.83, frames_total: 44\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 10 ***                       \n",
      "Av.reward: [last 10]: 20.80, [last 100]: 2.52, [all]: 22.91                       \n",
      "epsilon: 0.55, frames_total: 252\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 20 ***                       \n",
      "Av.reward: [last 10]: 14.10, [last 100]: 3.93, [all]: 18.71                       \n",
      "epsilon: 0.42, frames_total: 393\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 30 ***                       \n",
      "Av.reward: [last 10]: 12.30, [last 100]: 5.16, [all]: 16.65                       \n",
      "epsilon: 0.33, frames_total: 516\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 40 ***                       \n",
      "Av.reward: [last 10]: 10.90, [last 100]: 6.25, [all]: 15.24                       \n",
      "epsilon: 0.27, frames_total: 625\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 50 ***                       \n",
      "Av.reward: [last 10]: 10.80, [last 100]: 7.33, [all]: 14.37                       \n",
      "epsilon: 0.22, frames_total: 733\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 60 ***                       \n",
      "Av.reward: [last 10]: 9.80, [last 100]: 8.31, [all]: 13.62                       \n",
      "epsilon: 0.19, frames_total: 831\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 70 ***                       \n",
      "Av.reward: [last 10]: 10.90, [last 100]: 9.40, [all]: 13.24                       \n",
      "epsilon: 0.15, frames_total: 940\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 80 ***                       \n",
      "Av.reward: [last 10]: 9.90, [last 100]: 10.39, [all]: 12.83                       \n",
      "epsilon: 0.13, frames_total: 1039\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 90 ***                       \n",
      "Av.reward: [last 10]: 10.60, [last 100]: 11.45, [all]: 12.58                       \n",
      "epsilon: 0.11, frames_total: 1145\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 100 ***                       \n",
      "Av.reward: [last 10]: 10.20, [last 100]: 12.03, [all]: 12.35                       \n",
      "epsilon: 0.09, frames_total: 1247\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 110 ***                       \n",
      "Av.reward: [last 10]: 9.70, [last 100]: 10.92, [all]: 12.11                       \n",
      "epsilon: 0.08, frames_total: 1344\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 120 ***                       \n",
      "Av.reward: [last 10]: 9.60, [last 100]: 10.47, [all]: 11.90                       \n",
      "epsilon: 0.07, frames_total: 1440\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 130 ***                       \n",
      "Av.reward: [last 10]: 9.80, [last 100]: 10.22, [all]: 11.74                       \n",
      "epsilon: 0.06, frames_total: 1538\n",
      "Elapsed time:  16:07:1550610456\n",
      "\n",
      "*** Episode 140 ***                       \n",
      "Av.reward: [last 10]: 10.00, [last 100]: 10.13, [all]: 11.62                       \n",
      "epsilon: 0.05, frames_total: 1638\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 150 ***                       \n",
      "Av.reward: [last 10]: 9.90, [last 100]: 10.04, [all]: 11.50                       \n",
      "epsilon: 0.05, frames_total: 1737\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 160 ***                       \n",
      "Av.reward: [last 10]: 9.10, [last 100]: 9.97, [all]: 11.35                       \n",
      "epsilon: 0.04, frames_total: 1828\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 170 ***                       \n",
      "Av.reward: [last 10]: 9.40, [last 100]: 9.82, [all]: 11.24                       \n",
      "epsilon: 0.04, frames_total: 1922\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 180 ***                       \n",
      "Av.reward: [last 10]: 9.70, [last 100]: 9.80, [all]: 11.15                       \n",
      "epsilon: 0.04, frames_total: 2019\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 190 ***                       \n",
      "Av.reward: [last 10]: 9.60, [last 100]: 9.70, [all]: 11.07                       \n",
      "epsilon: 0.03, frames_total: 2115\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 200 ***                       \n",
      "Av.reward: [last 10]: 9.90, [last 100]: 9.67, [all]: 11.01                       \n",
      "epsilon: 0.03, frames_total: 2214\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 210 ***                       \n",
      "Av.reward: [last 10]: 9.60, [last 100]: 9.66, [all]: 10.95                       \n",
      "epsilon: 0.03, frames_total: 2310\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 220 ***                       \n",
      "Av.reward: [last 10]: 10.20, [last 100]: 9.72, [all]: 10.91                       \n",
      "epsilon: 0.03, frames_total: 2412\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 230 ***                       \n",
      "Av.reward: [last 10]: 9.30, [last 100]: 9.67, [all]: 10.84                       \n",
      "epsilon: 0.03, frames_total: 2505\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 240 ***                       \n",
      "Av.reward: [last 10]: 9.50, [last 100]: 9.62, [all]: 10.79                       \n",
      "epsilon: 0.02, frames_total: 2600\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 250 ***                       \n",
      "Av.reward: [last 10]: 8.80, [last 100]: 9.51, [all]: 10.71                       \n",
      "epsilon: 0.02, frames_total: 2688\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 260 ***                       \n",
      "Av.reward: [last 10]: 9.10, [last 100]: 9.51, [all]: 10.65                       \n",
      "epsilon: 0.02, frames_total: 2779\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 270 ***                       \n",
      "Av.reward: [last 10]: 9.60, [last 100]: 9.53, [all]: 10.61                       \n",
      "epsilon: 0.02, frames_total: 2875\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 280 ***                       \n",
      "Av.reward: [last 10]: 9.70, [last 100]: 9.53, [all]: 10.58                       \n",
      "epsilon: 0.02, frames_total: 2972\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 290 ***                       \n",
      "Av.reward: [last 10]: 9.90, [last 100]: 9.56, [all]: 10.55                       \n",
      "epsilon: 0.02, frames_total: 3071\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 300 ***                       \n",
      "Av.reward: [last 10]: 9.60, [last 100]: 9.53, [all]: 10.52                       \n",
      "epsilon: 0.02, frames_total: 3167\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 310 ***                       \n",
      "Av.reward: [last 10]: 9.30, [last 100]: 9.50, [all]: 10.48                       \n",
      "epsilon: 0.02, frames_total: 3260\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 320 ***                       \n",
      "Av.reward: [last 10]: 9.20, [last 100]: 9.40, [all]: 10.44                       \n",
      "epsilon: 0.02, frames_total: 3352\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 330 ***                       \n",
      "Av.reward: [last 10]: 9.40, [last 100]: 9.41, [all]: 10.41                       \n",
      "epsilon: 0.02, frames_total: 3446\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 340 ***                       \n",
      "Av.reward: [last 10]: 9.70, [last 100]: 9.43, [all]: 10.39                       \n",
      "epsilon: 0.02, frames_total: 3543\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 350 ***                       \n",
      "Av.reward: [last 10]: 9.30, [last 100]: 9.48, [all]: 10.36                       \n",
      "epsilon: 0.02, frames_total: 3636\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 360 ***                       \n",
      "Av.reward: [last 10]: 9.40, [last 100]: 9.51, [all]: 10.33                       \n",
      "epsilon: 0.02, frames_total: 3730\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 370 ***                       \n",
      "Av.reward: [last 10]: 8.60, [last 100]: 9.41, [all]: 10.29                       \n",
      "epsilon: 0.02, frames_total: 3816\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 380 ***                       \n",
      "Av.reward: [last 10]: 9.80, [last 100]: 9.42, [all]: 10.27                       \n",
      "epsilon: 0.02, frames_total: 3914\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 390 ***                       \n",
      "Av.reward: [last 10]: 9.40, [last 100]: 9.37, [all]: 10.25                       \n",
      "epsilon: 0.02, frames_total: 4008\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 400 ***                       \n",
      "Av.reward: [last 10]: 9.60, [last 100]: 9.37, [all]: 10.23                       \n",
      "epsilon: 0.02, frames_total: 4104\n",
      "Elapsed time:  16:07:1550610457\n",
      "\n",
      "*** Episode 410 ***                       \n",
      "Av.reward: [last 10]: 9.30, [last 100]: 9.37, [all]: 10.21                       \n",
      "epsilon: 0.02, frames_total: 4197\n",
      "Elapsed time:  16:07:1550610458\n",
      "\n",
      "*** Episode 420 ***                       \n",
      "Av.reward: [last 10]: 9.60, [last 100]: 9.41, [all]: 10.20                       \n",
      "epsilon: 0.02, frames_total: 4293\n",
      "Elapsed time:  16:07:1550610458\n",
      "\n",
      "*** Episode 430 ***                       \n",
      "Av.reward: [last 10]: 9.40, [last 100]: 9.41, [all]: 10.18                       \n",
      "epsilon: 0.02, frames_total: 4387\n",
      "Elapsed time:  16:07:1550610458\n",
      "\n",
      "*** Episode 440 ***                       \n",
      "Av.reward: [last 10]: 9.70, [last 100]: 9.41, [all]: 10.17                       \n",
      "epsilon: 0.02, frames_total: 4484\n",
      "Elapsed time:  16:07:1550610458\n",
      "\n",
      "*** Episode 450 ***                       \n",
      "Av.reward: [last 10]: 8.80, [last 100]: 9.36, [all]: 10.14                       \n",
      "epsilon: 0.02, frames_total: 4572\n",
      "Elapsed time:  16:07:1550610458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Episode 460 ***                       \n",
      "Av.reward: [last 10]: 9.80, [last 100]: 9.40, [all]: 10.13                       \n",
      "epsilon: 0.02, frames_total: 4670\n",
      "Elapsed time:  16:07:1550610458\n",
      "\n",
      "*** Episode 470 ***                       \n",
      "Av.reward: [last 10]: 9.50, [last 100]: 9.49, [all]: 10.12                       \n",
      "epsilon: 0.02, frames_total: 4765\n",
      "Elapsed time:  16:07:1550610458\n",
      "\n",
      "*** Episode 480 ***                       \n",
      "Av.reward: [last 10]: 9.30, [last 100]: 9.44, [all]: 10.10                       \n",
      "epsilon: 0.02, frames_total: 4858\n",
      "Elapsed time:  16:07:1550610458\n",
      "\n",
      "*** Episode 490 ***                       \n",
      "Av.reward: [last 10]: 9.30, [last 100]: 9.43, [all]: 10.08                       \n",
      "epsilon: 0.02, frames_total: 4951\n",
      "Elapsed time:  16:07:1550610458\n",
      "Average reward: 10.20\n",
      "Average number of steps (last 100 episodes): 10.05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104f0b320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qnet_agent = QNetAgent()\n",
    "\n",
    "steps_total = []\n",
    "frames_total = 0\n",
    "solved_after = 0\n",
    "solved = False\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "        frames_total += 1\n",
    "        \n",
    "        epsilon = calculate_epsilon(frames_total)\n",
    "        \n",
    "        action = qnet_agent.select_action(state, epsilon)\n",
    "        \n",
    "        new_state, reward, done, total = env.step(action)\n",
    "        \n",
    "        qnet_agent.optimize(state, action, new_state, reward, done)\n",
    "        \n",
    "        state = new_state\n",
    "        \n",
    "        if done:\n",
    "            steps_total.append(step)\n",
    "            mean_reward_100 = sum(steps_total[-100:])/100\n",
    "            \n",
    "            if (mean_reward_100 > score_to_solve and solved == False):\n",
    "                print(\"Solved after %i episodes\", i_episode)\n",
    "                solved_after = i_episode\n",
    "                solved = True\n",
    "            if(i_episode % report_interval == 0):\n",
    "                print(\"\\n*** Episode %i *** \\\n",
    "                      \\nAv.reward: [last %i]: %.2f, [last 100]: %.2f, [all]: %.2f \\\n",
    "                      \\nepsilon: %.2f, frames_total: %i\" \n",
    "                  % \n",
    "                  ( i_episode,\n",
    "                    report_interval,\n",
    "                    sum(steps_total[-report_interval:])/report_interval,\n",
    "                    mean_reward_100,\n",
    "                    sum(steps_total)/len(steps_total),\n",
    "                    epsilon,\n",
    "                    frames_total\n",
    "                          ) \n",
    "                  )\n",
    "\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(\"Elapsed time: \", time.strftime(\"%H:%M:%s\"))\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"Average reward: %.2f\" % (sum(steps_total)/num_episodes))\n",
    "print(\"Average number of steps (last 100 episodes): %.2f\" % (sum(steps_total[-100:])/100))\n",
    "if solved:\n",
    "      print(\"Solved after %i episodes\" % solved_after)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(\"Rewards\")\n",
    "plt.bar(torch.arange(len(steps_total)), steps_total, alpha=0.6, color='red')\n",
    "plt.show()\n",
    "      \n",
    "env.close()\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
