{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data/diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = V(torch.from_numpy(data[:, 0:-1]))\n",
    "y_data = V(torch.from_numpy(data[:, [-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 6) # notice, 8 inputs and...\n",
    "        self.l2 = torch.nn.Linear(6, 4)\n",
    "        self.l3 = torch.nn.Linear(4, 1) # one output\n",
    "            \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_hat = self.sigmoid(self.l3(out2))\n",
    "        \n",
    "        return y_hat\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6472551822662354\n",
      "1 0.6470708250999451\n",
      "2 0.6469066739082336\n",
      "3 0.6467588543891907\n",
      "4 0.6466266512870789\n",
      "5 0.6465083360671997\n",
      "6 0.64640212059021\n",
      "7 0.6463068127632141\n",
      "8 0.6462215185165405\n",
      "9 0.6461452841758728\n",
      "10 0.6460770964622498\n",
      "11 0.6460151672363281\n",
      "12 0.6459600925445557\n",
      "13 0.6459107995033264\n",
      "14 0.6458666920661926\n",
      "15 0.6458272933959961\n",
      "16 0.6457914113998413\n",
      "17 0.6457599997520447\n",
      "18 0.645731508731842\n",
      "19 0.6457056403160095\n",
      "20 0.6456828713417053\n",
      "21 0.6456624865531921\n",
      "22 0.6456440687179565\n",
      "23 0.6456275582313538\n",
      "24 0.6456126570701599\n",
      "25 0.6455991864204407\n",
      "26 0.6455874443054199\n",
      "27 0.6455767750740051\n",
      "28 0.6455670595169067\n",
      "29 0.6455581784248352\n",
      "30 0.6455507278442383\n",
      "31 0.6455435752868652\n",
      "32 0.6455367803573608\n",
      "33 0.6455307602882385\n",
      "34 0.6455256938934326\n",
      "35 0.6455211043357849\n",
      "36 0.6455165147781372\n",
      "37 0.6455128192901611\n",
      "38 0.645508885383606\n",
      "39 0.6455057859420776\n",
      "40 0.6455023884773254\n",
      "41 0.6455000638961792\n",
      "42 0.6454980373382568\n",
      "43 0.6454951763153076\n",
      "44 0.6454931497573853\n",
      "45 0.6454916000366211\n",
      "46 0.6454899311065674\n",
      "47 0.6454881429672241\n",
      "48 0.6454862356185913\n",
      "49 0.6454843878746033\n",
      "50 0.6454827785491943\n",
      "51 0.6454823613166809\n",
      "52 0.6454806923866272\n",
      "53 0.645479679107666\n",
      "54 0.6454781889915466\n",
      "55 0.6454777121543884\n",
      "56 0.645476758480072\n",
      "57 0.6454757452011108\n",
      "58 0.6454746723175049\n",
      "59 0.645473837852478\n",
      "60 0.6454735398292542\n",
      "61 0.6454721093177795\n",
      "62 0.6454713940620422\n",
      "63 0.6454706192016602\n",
      "64 0.6454703211784363\n",
      "65 0.6454693078994751\n",
      "66 0.6454689502716064\n",
      "67 0.6454671621322632\n",
      "68 0.6454668641090393\n",
      "69 0.6454666256904602\n",
      "70 0.6454655528068542\n",
      "71 0.645465075969696\n",
      "72 0.6454637050628662\n",
      "73 0.6454640626907349\n",
      "74 0.6454629302024841\n",
      "75 0.6454623341560364\n",
      "76 0.6454617977142334\n",
      "77 0.6454609632492065\n",
      "78 0.6454603672027588\n",
      "79 0.6454596519470215\n",
      "80 0.6454589366912842\n",
      "81 0.6454590559005737\n",
      "82 0.6454579830169678\n",
      "83 0.6454570889472961\n",
      "84 0.6454562544822693\n",
      "85 0.6454563736915588\n",
      "86 0.6454553604125977\n",
      "87 0.6454546451568604\n",
      "88 0.6454541087150574\n",
      "89 0.6454535722732544\n",
      "90 0.645452618598938\n",
      "91 0.6454523205757141\n",
      "92 0.6454511284828186\n",
      "93 0.6454513072967529\n",
      "94 0.6454502940177917\n",
      "95 0.6454500555992126\n",
      "96 0.6454490423202515\n",
      "97 0.6454482674598694\n",
      "98 0.6454482674598694\n",
      "99 0.6454471945762634\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    y_hat = model(x_data)\n",
    "    \n",
    "    loss = criterion(y_hat, y_data)\n",
    "    print(epoch, loss.data[0])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
